{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "mDgbUHAGgjLW",
        "dauF4eBmngu3",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "n3dbpmDWp1ck",
        "Ag9LCva-p1cl",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "nqoHp30x9hH9",
        "yiiVWRdJDDil",
        "EyNgTHvd2WFk",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pravinshukla108/Yes-Bank-Closing-Price-Prediction/blob/main/Yes_Bank_Closing_Price_Prediction_pravin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **YES BANK STOCK CLOSING PRICE PREDICTION**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Yes Bank is a well-known bank in the Indian financial domain. Since 2018, it has been in the news because of the fraud case involving Rana Kapoor. Owing to this fact, it was interesting to see how that impacted the stock prices of the company and whether Time series models or any other predictive models can do justice to such situations. This dataset has monthly stock prices of the bank since its inception and includes closing, starting, highest, and lowest stock prices of every month. The main objective is to predict the stock’s closing price of the month.**"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[ GitHub Link ](https://github.com/pravinshukla108/Yes-Bank-Closing-Price-Prediction.git)"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Predicting the stock’s closing price***\n",
        "***As we are very much familiar with the situation of \"YES BANK\" that it has experienced significiant volatility and faced challenges , including a high profile fraud case involving Rana Kapoor.***\n",
        "\n",
        "***So according to it our main objective of this project is to develop a reliable prediction model that can forecast the closing price of YES BANK stock based on its historical data and relevant market indicators***"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd  # Data manipulation and analysis\n",
        "import numpy as np  # Numerical operations and calculations\n",
        "import matplotlib.pyplot as plt  # Creating visualizations and plots\n",
        "\n",
        "import seaborn as sns  # High-level interface for statistical graphics\n",
        "from datetime import datetime  # Handling date and time operations\n",
        "import missingno as msno  # Visualizing missing data in datasets\n",
        "from sklearn.linear_model import LinearRegression  # Linear regression model\n",
        "from sklearn.linear_model import Ridge, RidgeCV  # Ridge regression models\n",
        "from sklearn.linear_model import Lasso, LassoCV  # Lasso regression models\n",
        "from sklearn.model_selection import train_test_split  # Splitting data into train and test sets\n",
        "from sklearn.model_selection import GridSearchCV  # Hyperparameter tuning through grid search\n",
        "from sklearn.preprocessing import StandardScaler  # Standardization of features\n",
        "from sklearn.preprocessing import MinMaxScaler  # Scaling features to a specific range\n",
        "from scipy.stats import *  # Contains statistical functions for hypothesis testing and probability distributions\n",
        "import warnings  # Managing and suppressing warnings\n",
        "warnings.filterwarnings('ignore')  # Suppress warnings\n",
        "\n",
        "# Import required metrics for model evaluation\n",
        "from sklearn.metrics import (\n",
        "    r2_score,  # R-squared (coefficient of determination) regression score function\n",
        "    mean_squared_error,  # Mean squared error regression loss\n",
        "    mean_absolute_percentage_error,  # Mean absolute percentage error regression loss\n",
        "    mean_absolute_error  # Mean absolute error regression loss\n",
        ")\n",
        "\n",
        "# Import linear regression models\n",
        "from sklearn import linear_model\n",
        "# Import Google Drive for data access\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "XkmRSPBKX7VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WPwmM7NrV1Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/yes bank ( ml regression )/data_YesBank_StockPrices.csv'\n",
        "yesbank = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "orxJTmJhYGI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "yesbank.head()"
      ],
      "metadata": {
        "id": "o0hrz7lWYOQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yesbank.tail()"
      ],
      "metadata": {
        "id": "6d9UaDM2WkCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "yesbank.shape"
      ],
      "metadata": {
        "id": "80vHWNQ-YgtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "yesbank.info()"
      ],
      "metadata": {
        "id": "B76mMzptYwuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(yesbank[yesbank.duplicated()])"
      ],
      "metadata": {
        "id": "Ke2SdsAmY4Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "yesbank.duplicated().sum()"
      ],
      "metadata": {
        "id": "pXksntLO4y_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "yesbank.isnull().sum()"
      ],
      "metadata": {
        "id": "Q_krffUHY7Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(yesbank.isnull())"
      ],
      "metadata": {
        "id": "BpDRgsgCY_nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.bar(yesbank,\n",
        "         fontsize=10,\n",
        "         figsize=(7,4),\n",
        "         color='purple')\n",
        "plt.title('Missing values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kz5ZBEzPEnyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In our dataset, there are 185 rows and 5 columns. In this data we have monthly stock price from July 2005 to November 2020. There are total five columns.  Date, Open, High, Low are the independent variables and Close is dependent variable. There are no Missing values and Duplicate values in the dataset.**"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "yesbank.columns"
      ],
      "metadata": {
        "id": "WU5neEUKZ6YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "yesbank.describe(include='all')"
      ],
      "metadata": {
        "id": "r4VRvXWsZ8ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Date** - Date of the record. It has month and year for a particular price.\n",
        "\n",
        "##**Open** - Opening price of the stock for that Month.\n",
        "\n",
        "##**High** - Highest price of the Month.\n",
        "\n",
        "##**Low** -  Lowest price of the Month.\n",
        "\n",
        "##**Close** -  Closing price of the stock for that Month"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in yesbank.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",yesbank[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "Fa7de8rEan7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "yesbank.head()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting Date to Datetime format(YYYY-MM-DD)\n",
        "yesbank['Date']= pd.to_datetime(yesbank['Date'].apply(lambda x: datetime.strptime(x, '%b-%y')))"
      ],
      "metadata": {
        "id": "lcPF2TyzIzRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# re-checking the dataset information regarding its datatype\n",
        "yesbank.info()"
      ],
      "metadata": {
        "id": "gd1U9e5eI1jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The machine learning models does not work on \"Date\" data so we need to convert it into numerical column.But, numerical date have no use in our respective dataframe to predict the goal. so here we make the \"Date\" column as dataframe index.***"
      ],
      "metadata": {
        "id": "g9Wfgi2DOS58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converting 'Date' feature to dataframe index.\n",
        "yesbank.set_index('Date',inplace=True)"
      ],
      "metadata": {
        "id": "YKOM87CKI9XD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the dataframe with index 'Date'\n",
        "yesbank.head()"
      ],
      "metadata": {
        "id": "kGF5EtDnJAqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The given dataset has 185 rows and 5 columns/features having no null and duplicates values.'Date' Feature is not in proper format so it is converted to 'datetime' format and make it to the Index of the dataframe as per our need to proceed further.***"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***UNIVARIATE ANALYSIS***"
      ],
      "metadata": {
        "id": "gH_qDD3Hr0Uw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# Initializing variable for independent features.\n",
        "indp_numeric_features = yesbank.describe().columns[0:3]\n",
        "indp_numeric_features\n",
        "\n",
        "# Define a list of colors\n",
        "colors = [\"m\", \"red\", \"green\",\"blue\",\"indigo\"]\n",
        "\n",
        "for i, col in enumerate(indp_numeric_features):\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.distplot(yesbank[col], color=colors[i])\n",
        "    plt.title('Distribution Curve')\n",
        "\n",
        "    # The Axes. axvline() function in axes module of matplotlib library is used to add a vertical line across the axis.\n",
        "    # It will show where the \"mean\" and \"median\" lie for each plot\n",
        "\n",
        "    plt.ylabel(\"Density\", size=14)\n",
        "    plt.axvline(yesbank[col].mean(), color=colors[i], linewidth=2)\n",
        "    plt.axvline(yesbank[col].median(), color='red', linestyle=\"dashed\", linewidth=2)\n",
        "\n",
        "    # using subplot() function of matplotlib to create boxplot in this figure itself\n",
        "    # Box plot is used to check outliers are present in respective features or not\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title('Box Plot')\n",
        "    graph = sns.boxplot(y=yesbank[col], color=colors[i])\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5LhA2GOQYbeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***I have picked the above chart because it combines histogram,kde and box plot that offers a comprehensive visualization of the data distribution and outliner as well. It allows for a better understanding of the distribution's characteristics, such as its shape, peaks, and deviations from a normal distribution.The combined plot provides a richer visualization that incorporates both the frequency-based information from the histogram and the smooth density estimate from the KDE plot and in Box plot the quartile divides the data in four equal parts from which we can recognize max.,min.,mean and median of the data.***"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***From the above chart it is clearly visualize that it is right/positively skewed and has to be converted to normal distribution and by converting it to normal distribution outliners can be removed.***"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Currently can't say that it has a positive or negative impact but it is helpful to understand and decide upon the requirement of transformation of the features for Model implementation.Here we will use log transformation to convert it into normal distribution and to remove outliner.***"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Plotting the histogram to see Dependent variable 'Close' distribution which we need to predict later\n",
        "plt.figure(figsize=(9,7))\n",
        "sns.distplot(yesbank['Close'],color=\"indigo\")\n",
        "plt.title(\"Close stock price distirbution\")"
      ],
      "metadata": {
        "id": "opBbN1TgHn3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***I have picked the above chart because it combines both histogram and kde plot that offers a comprehensive visualization of the data distribution. It allows for a better understanding of the distribution's characteristics, such as its shape, peaks, and deviations from a normal distribution.The combined plot provides a richer visualization that incorporates both the frequency-based information from the histogram and the smooth density estimate from the KDE plot.***"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***From the above chart it is clearly visualize that it is right/positively skewed and has to be converted to normal distribution.***"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Currently can't say that it has a positive or negative impact but it is helpful to understand and decide upon the requirement of transformation of the features for Model implementation.Here we will use log transformation to convert it into normal distribution.***"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "#  Plotting the Log Transformation to see Dependent variable 'Close' distribution which we need to predict later.\n",
        "plt.figure(figsize=(9,5))\n",
        "sns.distplot(np.log(yesbank['Close']),color=\"r\")\n",
        "plt.title(\"Close Price Distribution after log transformation\")"
      ],
      "metadata": {
        "id": "hC-M_j_1KuKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***I have used the log transformation because the distribution is not much skewed, and log transformation is helpful to bring the normal pattern in distribution of dependent feature.Beacuse of the Log transformation outliners are removed.***"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Log transformation is sufficient to bring the noraml distribution.It shows the mean is pumped and the frequent points are not near to mean. The plot clarifies about the bubble price of Yes Bank stock remained for very less time.***"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***It helps to observe the peak and vallyes in closing stock price.The inflated price at mean is temporary as it is a bubble point and after this the price got decline tremendously because of the fraud case which happened in 2018.***"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# log tranformation to convert Independent Feautres to normal distribution\n",
        "\n",
        "for col in indp_numeric_features:\n",
        "    plt.figure(figsize=(30, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(\"Distribution Curve\")\n",
        "\n",
        "# np.log() is a method in numpy library to convert our dataset values into log transformation to get a normal distribution curve\n",
        "\n",
        "    feature_to_log = np.log(yesbank[col])  # assign log tranformation value into a variable\n",
        "    sns.distplot(feature_to_log, color=\"green\")\n",
        "\n",
        "# The Axes. axvline() function in axes module of matplotlib library is used to add a vertical line across the axis.\n",
        "# It will show where the \"mean\" and \"median\" lie for each plot\n",
        "\n",
        "    plt.ylabel(\"Density\", size=18)\n",
        "    plt.axvline(feature_to_log.mean(),color='magenta',linewidth=2)\n",
        "    plt.axvline(feature_to_log.median(),color='red',linestyle=\"dashed\",linewidth=2)\n",
        "\n",
        "# creating boxplot to see if there is any outliers in any feature or not\n",
        "# using subplot() function of matplotlib to create boxplot in this figure itself\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(\"Box plot\")\n",
        "    sns.boxplot(y=feature_to_log, color=\"blue\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GzwM-A34NamJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***I have used the log transformation because the distribution is not much skewed, and log transformation is helpful to bring the normal pattern in distribution of dependent feature.Beacuse of the Log transformation outliners are removed.***"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Log transformation is sufficient to bring the noraml distribution.The plot clarifies about the bubble price of Yes Bank stock remained for very less time.we can see from the distribution curve that mean is now closer median.***\n",
        "\n",
        "***From the above boxplot after log transformation, we can see outliner are removed and we have approximate result of quartiles for independent features which are as follows-***\n",
        "\n",
        "* For feature Open- Lower Quartile(Q1)- 3.6 ,Median(Q2)- 4.3, Upper Quartile(Q3)- 5.0\n",
        "* For feature High- Lower Quartile(Q1)- 3.7 ,Median(Q2)- 4.4, Upper Quartile(Q3)- 5.2\n",
        "* For feature Low- Lower Quartile(Q1)- 3.3 ,Median(Q2)- 4, Upper Quartile(Q3)- 4.9"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***It helps to observe the peak and vallyes in stock prices.The inflated price at mean is temporary as it is a bubble point and after this the price got decline tremendously because of the fraud case which happened in 2018.***\n",
        "\n",
        "***After the log transformation, the outliner are removed and the distribution is converted to normal pattern which will suffice the model requirements and help to achieve better accuracy of our models,so we can say that the transformation has a positive impact.***"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ***BIVARIATE ANALYSIS***"
      ],
      "metadata": {
        "id": "yOHH18Itu7OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Chart - 5 visualization code\n",
        "# Visualizing yesbank stock closing price over the time.\n",
        "\n",
        "# Set the theme\n",
        "sns.set_theme(style=\"darkgrid\")\n",
        "\n",
        "# Adjust figure size\n",
        "sns.set(rc={'figure.figsize':(15, 8)})\n",
        "\n",
        "# Create the lineplot\n",
        "sns.lineplot(x=\"Date\", y=\"Close\", data=yesbank, color='red')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Yes Bank Closing Price Over Time')\n",
        "plt.xlabel('Year')\n",
        "plt.grid(True)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "I526mOtO1xc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***A line plot was chosen to visualize the closing prices over time. Line plots are commonly used to show trends and changes in data over a continuous variable, such as time.***"
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***We can observe the overall trend of the closing prices over time.***"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***As we know the stock closing price serves as a benchmark for determining how a stock performs and also help investors comprehend how its value has changed over time.From the above plot it is seen that stock closing price diminishes continously after 2018 ,so it is alarming for the yes bank to cope with this situation as closing price is that one price which drives investors to invest in a stock or not.So, as per scnerio the insights have a negative impact on business, but by observing the trend they must try to restrict the stock manipulation to become stable in terms of revenue.***"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Define custom colors\n",
        "colors = ['#FF4500', '#0077b6']\n",
        "\n",
        "# Plot Open vs Close with custom colors\n",
        "ax = yesbank.loc[:, ['Open', 'Close']].tail(35).plot(kind='bar', figsize=(20, 8), color=colors)\n",
        "\n",
        "# Customize grid lines\n",
        "plt.grid(which='major', linestyle='-', linewidth='0.9', color='green')\n",
        "plt.grid(which='minor', linestyle=':', linewidth='0.9', color='orange')\n",
        "\n",
        "# Customize axis labels and tick labels\n",
        "ax.set_xlabel('Time', fontsize=15, color='lime')\n",
        "ax.set_ylabel('Value', fontsize=15, color='crimson')\n",
        "ax.tick_params(axis='both', which='major', labelsize=14, colors='darkviolet')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The chart shows the trend of Open and Close prices over time.Blue bar indicates opening price of that month, orange bar indicates closing price of that month.***"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "***The graph above indicates that after 2018, the stock price of YES Bank drops, making it unwise for investors to place their money in the company.***\n",
        "\n",
        "* ***The closing price reached its peak 4 times of above 350Rs, in the month of August 2017, January 2018, April 2018, July 2018 .***\n",
        "\n",
        "* ***The opening and closing prices were at lowest during these 4 months - August 2020, September 2020, October 2020, November 2020 .***\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The insight that the stock price of YES Bank has dropped after 2018 suggests that the company may be facing challenges and may not be performing well, which could lead to a negative impact on the business. This insight may discourage potential investors from investing in the company and could lead to negative growth.***"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# comparing High and Low Prices\n",
        "\n",
        "# Create a range of colors for color-coding\n",
        "\n",
        "colors = np.arange(len(yesbank))\n",
        "color_map = plt.get_cmap('gist_rainbow_r', len(yesbank))\n",
        "\n",
        "# Create a range of sizes for size variation\n",
        "\n",
        "sizes = 50 + 10 * np.arange(len(yesbank))\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Create the scatter plot with data labels, color-coding, and size variation\n",
        "\n",
        "plt.scatter(yesbank['High'], yesbank['Low'],c=colors, cmap=color_map, s=sizes, alpha=0.35)\n",
        "plt.xlabel('High Price')\n",
        "plt.ylabel('Low Price')\n",
        "plt.title('High vs Low Prices Over Time (Color-Coded by Time Progression)')\n",
        "plt.colorbar(label='Time Progression')\n",
        "plt.savefig('scatter_plot.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***it is a good way to visualize the relationship between two variables. In this case, the two variables are the high and low prices of a product.***"
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***There is a positive correlation between the high and low prices. This means that when the high price increases, the low price also tends to increase.***\n",
        "\n",
        "* ***There is a lot of variation in the data. This means that there is not a perfect relationship between the high and low prices.***"
      ],
      "metadata": {
        "id": "GgUl6u7piVQ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Set prices that are competitive and that will attract customers. Identify opportunities to increase prices without losing customers. Track the impact of changes in prices on sales.***"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Visualizing yesbank stock opening price over the time.\n",
        "\n",
        "# Sets the Seaborn style and figure size\n",
        "sns.set_theme(style=\"ticks\")\n",
        "sns.set(rc={'figure.figsize': (11, 8)})\n",
        "\n",
        "# Creates the lineplot for opening prices\n",
        "plt.figure(figsize=(11, 8))\n",
        "sns.lineplot(x=\"Date\", y=\"Open\", data=yesbank, color='green')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Yes Bank Opening Price Over Time', fontsize=16)\n",
        "plt.xlabel('Year', fontsize=12 , color='red')\n",
        "plt.ylabel('Opening Price', fontsize=12, color='blue')\n",
        "\n",
        "# Add grid lines\n",
        "plt.grid(True, linestyle='solid', alpha=1)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Line plot is used to show the progression of a variable over time or any continuous variable that has an inherent order. They are particularly useful for visualizing trends, seasonality, and changes in values over time.***"
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***From the above plot we can say that there is a increasing trend from 2009 which reach at its highest during 2017 but price started falling after 2018 because of Rana Kapoor's fraud case***"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***As we know the stock closing price serves as a benchmark for determining how a stock performs and also help investors comprehend how its value has changed over time.From the above plot it is seen that stock closing price diminishes continously after 2018 ,so it is alarming for the yes bank to cope with this situation as closing price is that one price which drives investors to invest in a stock or not.So, as per scnerio the insights have a negative impact on business, but by observing the trend they must try to restrict the stock manipulation to become stable in terms of revenue.***"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "\n",
        "\n",
        "# Create a figure and set its size\n",
        "plt.figure(figsize=(24, 12))\n",
        "\n",
        "# Plot the open, high, and low prices with custom line styles and colors\n",
        "plt.plot(yesbank.index, yesbank['Open'], label='Open', color='blue', linestyle='-', linewidth=2)\n",
        "plt.plot(yesbank.index, yesbank['High'], label='High', color='green', linestyle='--', linewidth=2)\n",
        "plt.plot(yesbank.index, yesbank['Low'], label='Low', color='red', linestyle='-.', linewidth=2)\n",
        "\n",
        "\n",
        "# Customize the plot labels and tick labels\n",
        "\n",
        "plt.legend(loc='upper right', fontsize=14, title='Price Categories', title_fontsize=16)\n",
        "\n",
        "plt.xlabel('Date', fontsize=16, color='lime')\n",
        "plt.ylabel('Price', fontsize=16, color='crimson')\n",
        "plt.title('Yes Bank Price - Open, High, and Low', fontsize=20, color='red')\n",
        "plt.tick_params(axis='both', which='major', labelsize=16, colors='darkviolet')\n",
        "\n",
        "\n",
        "# Add grid lines\n",
        "plt.grid(True, linestyle='--', alpha=0.9)\n",
        "\n",
        "# Add data labels to indicate price categories\n",
        "plt.text(yesbank.index[-1], yesbank['Open'].iloc[-1], 'Open', fontsize=12, color='blue', verticalalignment='center')\n",
        "plt.text(yesbank.index[-1], yesbank['High'].iloc[-1], 'High', fontsize=12, color='green', verticalalignment='bottom')\n",
        "plt.text(yesbank.index[-1], yesbank['Low'].iloc[-1], 'Low', fontsize=12, color='red', verticalalignment='top')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The specific chart used, is a line plot that displays the open, high, and low prices of Yes Bank stock over time. This chart was chosen because it is suitable for visualizing time series data, making it easier to identify trends, fluctuations, and historical peaks and valleys in stock prices. Additionally, using custom line styles and colors for each price category enhances the clarity of the visualization.***\n"
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The insights that can be derived from the chart include:\n",
        "\n",
        "* Price Trends: Analyzing whether the stock prices have been consistently rising (positive trend), falling (negative trend), or fluctuating (volatility) over the observed time period.\n",
        "* Historical Extremes: Identifying historical peaks (high prices) and valleys (low prices) in the stock's performance.\n",
        "*  Comparing Price Categories: Comparing the behavior of open, high, and low prices over time, which can reveal patterns or differences in how these categories move.\n",
        "\n",
        "\n",
        "***The insights found from the chart are:***\n",
        "- Yes Bank's stock price has been steadily increasing from 2006 to 2018.\n",
        "- The stock price peaked in 2018 and has been steadily decreasing since then.\n",
        "- The stock price has been consistently lower than the opening price since 2018.\n",
        "\n",
        "\n",
        "***As we can see that All the prices shows almost similar trends with each other which means that this features may be strongly correlated with each other .***"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The gained insights from the chart can potentially help in making informed investment and business decisions. Here's how:*\n",
        "\n",
        "***Positive Impact:***\n",
        "\n",
        "Investment Strategies: Investors can use insights into price trends and historical extremes to make strategic decisions on buying or selling Yes Bank stock.\n",
        "Risk Assessment: Understanding price volatility is essential for risk management. Investors can assess and mitigate risk more effectively.\n",
        "Timing: Identifying patterns or trends can assist in timing investment decisions for positive returns.\n",
        "\n",
        "\n",
        "***Negative Impact:***\n",
        "\n",
        "Negative Growth Potential: If the chart shows a consistent and prolonged downward trend in stock prices, this could lead to negative growth. Investors may experience losses, and businesses associated with Yes Bank may face challenges.\n",
        "Volatility Risk: High volatility, especially if it leads to erratic price fluctuations, can introduce uncertainty and risk for both investors and businesses.\n",
        "***The gained insights will help creating a positive business impact because it shows that Yes Bank's stock price has been steadily decreasing since 2018. This could be a sign that the company is not doing well and may need to make changes in order to improve their stock price. There are no insights that lead to negative growth because the stock price is already decreasing.***\n"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "#Violin Plot: Distribution of Open, High, Low, and Close Prices\n",
        "\n",
        "# Data preparation: Select the price columns\n",
        "price_data = yesbank[['Open', 'High', 'Low', 'Close']]\n",
        "\n",
        "# Set plot style and figure size\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create the violin plot\n",
        "sns.violinplot(data=price_data, palette=\"Set2\", inner=\"stick\", scale=\"width\")\n",
        "\n",
        "# Customize the plot\n",
        "plt.title(\"Distribution of Open, High, Low, and Close Prices for Yes Bank Stock\", fontsize=16)\n",
        "plt.xlabel(\"Price Category\", fontsize=14)\n",
        "plt.ylabel(\"Price Value\", fontsize=14)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***I picked this specific chart because it shows the distribution of open, high, low, and close prices for Yes Bank stock. This chart is helpful in understanding the stock's performance and trends.***"
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The insights found from the chart are:***\n",
        "- The open and close prices for Yes Bank stock are relatively similar, indicating that the stock is relatively stable.\n",
        "- The high and low prices for Yes Bank stock are relatively similar, indicating that the stock is relatively stable.\n",
        "- The stock's price is relatively stable, indicating that the stock is relatively stable."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The gained insights will help creating a positive business impact because the stock's price is relatively stable. This means that the stock is relatively stable and is not experiencing any major fluctuations. This is a good sign for investors and can lead to positive growth. There are no insights that lead to negative growth because the stock's price is relatively stable.***\n",
        "\n",
        "- This is a chart showing the distribution of open, high, low, and close prices for Yes Bank stock.\n",
        "- The open and close prices for Yes Bank stock are relatively similar, indicating that the stock is relatively stable.\n",
        "- The high and low prices for Yes Bank stock are relatively similar, indicating that the stock is relatively stable.\n",
        "- The stock's price is relatively stable, indicating that the stock is relatively stable."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visuaization code\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = yesbank.corr()\n",
        "\n",
        "# Set figure size and create the heatmap\n",
        "plt.figure(figsize=(13, 9))\n",
        "heatmap = sns.heatmap(correlation_matrix, annot=True, cmap=\"viridis\", linewidths=.5, square=True)\n",
        "\n",
        "# Customize the plot\n",
        "plt.title(\"Correlation Heatmap for Yes Bank Stock Prices\", fontsize=16)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***I picked the specific chart because it is a correlation heatmap for Yes Bank Stock Prices. This chart is useful for understanding the relationship between different stock prices.***"
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The insights found from the chart are that there is a strong positive correlation between the stock prices. This means that when one stock price increases, the other stock prices also tend to increase.***"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(yesbank ,diag_kind=\"kde\")"
      ],
      "metadata": {
        "id": "E618iUzWcXpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The pair plot is suitable when you want to visualize the relationships between multiple variables in a dataset. It creates a grid of scatter plots, making it easier to identify patterns, trends, and potential outliers.***"
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The pair plot allows for a comprehensive examination of the pairwise relationships, helping to understand how variables interact with each other. On the other hand, the pair plot provides a more comprehensive view of the relationships by displaying scatter plots for all possible variable combinations.***"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yesbank1= yesbank.iloc[:,0:].copy()\n",
        "print(yesbank1.head())"
      ],
      "metadata": {
        "id": "fViQLLxYjgPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MACD**"
      ],
      "metadata": {
        "id": "yxos2KTqPl5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the short Exponential Moving Average (EMA) with a span of 12 periods\n",
        "shortEMA = yesbank['Close'].ewm(span=12, adjust=False).mean()\n",
        "\n",
        "# Calculate the long Exponential Moving Average (EMA) with a span of 26 periods\n",
        "longEMA = yesbank['Close'].ewm(span=26, adjust=False).mean()\n",
        "\n",
        "# Calculate the MACD (Moving Average Convergence Divergence) by subtracting the long EMA from the short EMA\n",
        "MACD = shortEMA - longEMA\n",
        "\n",
        "# Calculate the signal line by taking a 9-period EMA of the MACD\n",
        "signal = MACD.ewm(span=9, adjust=False).mean()\n",
        "\n",
        "# Add the MACD values to the DataFrame as a new column named 'macd'\n",
        "yesbank['macd'] = MACD\n",
        "\n",
        "# Add the MACD signal line values to the DataFrame as a new column named 'macd_signal'\n",
        "yesbank['macd_signal'] = signal\n"
      ],
      "metadata": {
        "id": "Y5wgmf7FPCwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RSI**"
      ],
      "metadata": {
        "id": "zJORqDM831wN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the price changes (differences) for each day\n",
        "delta = yesbank['Close'].diff()\n",
        "\n",
        "# Calculate gains (positive price changes) and set losses to 0\n",
        "gain = delta.mask(delta < 0, 0)\n",
        "\n",
        "# Calculate losses (negative price changes) and set gains to 0\n",
        "loss = -delta.mask(delta > 0, 0)\n",
        "\n",
        "# Calculate the average gain over a rolling window of 14 periods\n",
        "avg_gain = gain.rolling(window=14).mean()\n",
        "\n",
        "# Calculate the average loss over a rolling window of 14 periods\n",
        "avg_loss = loss.rolling(window=14).mean()\n",
        "\n",
        "# Calculate the relative strength (RS) which is the ratio of average gain to average loss\n",
        "rs = avg_gain / avg_loss\n",
        "\n",
        "# Calculate the Relative Strength Index (RSI) using the formula: RSI = 100 - (100 / (1 + RS))\n",
        "rsi = 100 - (100 / (1 + rs))\n",
        "\n",
        "# Add the RSI values to the DataFrame as a new column 'rsi'\n",
        "yesbank['rsi'] = rsi\n"
      ],
      "metadata": {
        "id": "8GY7E6AXQPEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Null hypothesis H0: There is no significant difference in the predictive power of the RSI and a random walk model on the closing price of the stock.***\n",
        "\n",
        "***Alternative hypothesis H1: The RSI provides a significant improvement in predicting the closing price of the stock compared to a random walk mode.***"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Calculate random walk predictions by shifting the closing prices by one time period\n",
        "rw_predictions = yesbank['Close'].shift(1)\n",
        "\n",
        "# Calculate RSI predictions using a simple rule-based strategy:\n",
        "# If RSI > 50, the prediction is the current closing price; otherwise, it's the previous closing price.\n",
        "rsi_predictions = yesbank['Close'].where(yesbank['rsi'] > 50, yesbank['Close'].shift(1)) \\\n",
        "    .where(yesbank['rsi'] < 50, yesbank['Close'].shift(1))\n",
        "\n",
        "# Calculate prediction errors for both RSI and random walk models\n",
        "rsi_errors = yesbank['Close'] - rsi_predictions\n",
        "rw_errors = yesbank['Close'] - rw_predictions\n",
        "\n",
        "# Perform a paired t-test on the prediction errors to determine if there's a significant difference\n",
        "# between the RSI model and the random walk model.\n",
        "t_stat, p_val = ttest_rel(rsi_errors, rw_errors)\n",
        "\n",
        "# Print the results of the t-test\n",
        "if p_val < 0.05:\n",
        "    print(\"Reject null hypothesis.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis.\")\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***From this testing we can conlude that there is no significant difference in the predictive power of the RSI and a random walk model on the closing price of the stock.***"
      ],
      "metadata": {
        "id": "xmBc1e-FWkDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Paired t-test was performed to obtain the P-value.***"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The RSI and random walk models are applied to the same set of data, and the prediction errors are calculated for each model on the same set of observations. Therefore, the data is paired, and a paired test is appropriate***\n",
        "\n",
        "***I want to test whether there is any significant difference between the mean prediction errors of the RSI and random walk models. The paired t-test is designed to test the difference between the means of the paired data.***"
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Null hypothesis H0:*** *There is no significant difference in the predictive power of the MACD indicator and a simple moving average strategy on the closing price of the stock.*\n",
        "***Alternative hypothesis H1:*** *The MACD indicator provides a significant improvement in predicting the closing price of the stock compared to a simple moving average strategy.*"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# generate predictions using MACD and SMA strategies\n",
        "yesbank['macd_pred'] = yesbank['Close'] + yesbank['macd_signal']\n",
        "yesbank['sma'] = yesbank['Close'].rolling(window=14).mean()\n",
        "yesbank['sma_pred'] = yesbank['sma'].shift(1)"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate prediction errors\n",
        "macd_errors = yesbank['macd_pred'] - yesbank['Close']\n",
        "sma_errors = yesbank['sma_pred'] - yesbank['Close']"
      ],
      "metadata": {
        "id": "pxrvGwcV6EI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate prediction errors\n",
        "macd_errors = yesbank['macd_pred'] - yesbank['Close']\n",
        "sma_errors = yesbank['sma_pred'] - yesbank['Close']"
      ],
      "metadata": {
        "id": "Ir3_odOk6OVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform paired t-test\n",
        "t_stat, p_val = ttest_rel(macd_errors, sma_errors)\n",
        "\n",
        "# print results\n",
        "if p_val < 0.05:\n",
        "    print(\"Reject null hypothesis.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis.\")"
      ],
      "metadata": {
        "id": "0aOc-A1Y6UWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*From above test you can see there is no significant difference in the predictive power of the MACD indicator and a simple moving average strategy on the closing price of the bank stock.*"
      ],
      "metadata": {
        "id": "qdTqWzj5XqgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***A paired t-test was performed to obtain the P-value.***\n",
        "\n",
        "***we can then use the resulting p-value to determine whether to reject or fail to reject the null hypothesis***"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The paired t-test is a parametric test that assumes that the differences between the paired measurements follow a normal distribution.***\n",
        "\n",
        "***the paired t-test is a useful and widely-used statistical test for comparing paired data and testing hypotheses about the difference between two means.***"
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis - Predict the stock’s closing price of the month.\n",
        "\n",
        "Alternate Hypothesis - Not able to predict the stock’s closing price of the month."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf"
      ],
      "metadata": {
        "id": "fRmqjZikYMz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indep_var=yesbank[['High','Low','Open']]\n",
        "dep_var=yesbank['Close']"
      ],
      "metadata": {
        "id": "8HOMTb357--5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indep_var = sm.add_constant(indep_var) ## let's add an intercept (beta_0) to our model\n",
        "model = sm.OLS(dep_var, indep_var).fit() ## sm.OLS(output, input)\n",
        "predictions = model.predict(indep_var)"
      ],
      "metadata": {
        "id": "EQTgD6Md7_Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "3b0Ourqa7_oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***I have used statsmodel.api statistical test to obtain the P-value.***"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used this statistical test because I was quite aware of this test from my earlier self projects so i used it."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# Missing Values/Null Values Count\n",
        "yesbank.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Our dataset has no missing or null values***"
      ],
      "metadata": {
        "id": "30FVoOQH8u2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Since our data does not contain any missing values . so there is no need to impute missing values.**"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***IQR (INTER QUANTILE RATE) :-***"
      ],
      "metadata": {
        "id": "L0M8ABy085yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "# Function to detect outliers using the IQR method\n",
        "def detect_outlier_iqr(data_column):\n",
        "  # Calculate the first quartile (Q1) and third quartile (Q3)\n",
        "  q1 = data_column.quantile(0.25)\n",
        "  q3 = data_column.quantile(0.75)\n",
        "\n",
        "  # Calculate the interquartile range (IQR)\n",
        "  iqr = q3 - q1\n",
        "\n",
        "  # Calculate the lower fence and upper fence\n",
        "  lower_fence = q1 - (1.5 * iqr)\n",
        "  upper_fence = q3 + (1.5 * iqr)\n",
        "\n",
        "  # Identify the outliers that fall outside the lower and upper fences\n",
        "  outlier = data_column[(data_column < lower_fence) | (data_column > upper_fence)]\n",
        "\n",
        "  return outlier\n",
        "\n",
        "# Apply the function to the 'Close' column of the 'yesbank' DataFrame to detect outliers\n",
        "outlier = detect_outlier_iqr(yesbank['Close'])\n",
        "\n",
        "# Display the outliers (if any)\n",
        "print(outlier)\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define custom colors\n",
        "custom_colors = [\"m\", \"g\", \"r\",\"cyan\"]\n",
        "\n",
        "# Create a boxplot with custom colors to identify outliers\n",
        "plt.figure(figsize=(13, 8))\n",
        "sns.boxplot(data=yesbank, palette=custom_colors)\n",
        "plt.title(\"Box Plot To Identify Outliers\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ts6iRaq8fTTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The technique that i used for outliers treatment is \"Inter Quantile Range\" as the data doesn't follow a normal distribution, we will calculate the outlier data points using the statistical method called interquartile range (IQR) instead of using Z-score.***"
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***There is no need of categorical encoding in this dataset as all our columns are numerics and datetime format.***"
      ],
      "metadata": {
        "id": "YiACDCsRni13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)\n",
        "\n",
        "### ***There is no need to do any textual data preprocessing as it is not required according to our dataset***"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "\n",
        "# Calculate the correlation matrix for the DataFrame\n",
        "corr = yesbank.corr()\n",
        "\n",
        "# Create a colormap for the heatmap with specific color settings\n",
        "cmap = sns.diverging_palette(450, 150, l=55, center=\"dark\", as_cmap=True)\n",
        "\n",
        "# Define a function to magnify the heatmap on hover\n",
        "def magnify():\n",
        "    return [\n",
        "        dict(selector=\"th\", props=[(\"font-size\", \"10pt\")]),\n",
        "        dict(selector=\"td\", props=[('padding', \"0em 0em\")]),\n",
        "        dict(selector=\"th:hover\", props=[(\"font-size\", \"14pt\")]),\n",
        "        dict(selector=\"tr:hover td:hover\", props=[('max-width', '250px'), ('font-size', '14pt')])\n",
        "    ]\n",
        "\n",
        "# Create the styled correlation heatmap with the specified colormap and hover effect\n",
        "corr.style.background_gradient(cmap, axis=1) \\\n",
        "    .set_properties(**{'max-width': '85px', 'font-size': '12pt'}) \\\n",
        "    .set_caption(\"Hover to magnify\") \\\n",
        "    .set_precision(2) \\\n",
        "    .set_table_styles(magnify())\n",
        "\n"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "\n",
        "# Feature selection for Independent and dependent variable\n",
        "independent_variables = [col for col in yesbank.columns if col != 'Close']\n",
        "dependent_variable = 'Close'\n"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "\n",
        "# Log-transform the 'Open', 'High', 'Low', and 'Close' columns\n",
        "columns_to_log_transform = ['Open', 'High', 'Low', 'Close']\n",
        "\n",
        "for column in columns_to_log_transform:\n",
        "    yesbank[column] = np.log(yesbank[column])\n",
        "\n",
        "# Check the correlation between independent and dependent variables after data transformation\n",
        "cor_log = yesbank1.corr()\n",
        "\n",
        "# Create a heatmap to visualize the correlation\n",
        "sns.heatmap(cor_log, annot=True, cmap='plasma')\n",
        "yesbank.head()"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*****Data Transformation is required and I have used log transformation(np.log) for the data which is given. The reasons behind the transformation are as follows-*****\n",
        "\n",
        "* *Data which is given is right skewed so to make the distribution normal and symmetric transforamtion is required which will help to implement model correctly and pricesly which help us to reach towards desired accuracy*.\n",
        "\n",
        "\n",
        "* *After treating outliers the correltion b/w independent and dependent variable got distorted so to restore that, transformation is required and as we can see from the above heatmap the correlation are restored which will make our model more accurate for prediction, but it has multicollinearity and to deal with it we have to drop that feature which is least correlated with the target variable, but by doing so we lose the valuable information as our dataset is small, so we continue with the multicollinearity and check how our model behaves with this phenomena*."
      ],
      "metadata": {
        "id": "kqTBYxTIzB-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "\n",
        "# Define the independent variables (features) and the dependent variable (target)\n",
        "independent_var = ['Open', 'High', 'Low']\n",
        "dependent_var = 'Close'\n",
        "x = np.log10(yesbank[independent_var])  # Log-transform the selected features\n",
        "y = np.log10(yesbank['Close'])  # Log-transform the target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1)\n",
        "# - x_train and y_train will be used for training the model.\n",
        "# - x_test and y_test will be used for evaluating the model's performance.\n",
        "\n",
        "# Scaling your data using Min-Max scaling\n",
        "scaler = MinMaxScaler()\n",
        "x_train = scaler.fit_transform(x_train)  # Fit and transform the training data\n",
        "x_test = scaler.transform(x_test)  # Transform the testing data using the same scaler\n",
        "# Min-Max scaling scales the data to a range between 0 and 1, making it suitable for many machine learning algorithms.\n"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?\n",
        "\n",
        "***I have used MinMaxScaler.***\n",
        "*I chose this method because it preserves the relative relationships between the data points and is suitable when the features have different scales. Scaling to a specific range helps algorithms that are sensitive to the magnitude of the features to perform better and converge faster.*"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***No there is no need for dimensionality reduction in our dataset as it a small dataset with 185 rows and 5 columns.***"
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "# Splitting data into training and testing sets with a 75-25 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=1)\n",
        "\n",
        "# Print the shapes of the training and testing sets\n",
        "print(\"Training set shape:\", X_train.shape)  # Displays the shape of the training data\n",
        "print(\"Testing set shape:\", X_test.shape)  # Displays the shape of the testing data\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***I used Train test split ,because this method is a fast and easy procedure to perform and also help to comapre between our model resut and given model result.***\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PPZ_KfeQV277"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***No the data is not imbalanced as our dependent variable is evenly distributed over all datapoints and also this type of problem mainly occur in classification models.***"
      ],
      "metadata": {
        "id": "nEOqaBs2WW3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 ***Linear Regression***"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***For building this model I am using Linear Regression machine learning algorithm.It is a statistical method that is used for predictive analysis.***\n",
        "***Linear regression algorithm shows a linear relationship between a dependent variable and one or more independent variables.***"
      ],
      "metadata": {
        "id": "QS6EBiugXGia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "reg = LinearRegression().fit(X_train, y_train)\n",
        "# Calculate the R-squared (coefficient of determination) for the training data\n",
        "train_r_squared = reg.score(X_train, y_train)\n",
        "# Print the model coefficients\n",
        "model_coefficients = reg.coef_\n",
        "print(\"Model Coefficients:\", model_coefficients)\n",
        "# Predict on the model\n",
        "y_pred = reg.predict(X_test)\n",
        "# Plot the predicted and actual values\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(10 ** (y_pred), color='darkviolet', label=\"Predicted\")\n",
        "plt.plot(np.array(10**(y_test)),color='crimson', label=\"Actual\")\n",
        "plt.legend()\n",
        "plt.title(\"Predicted vs Actual Values\")\n",
        "plt.xlabel(\"Data Point\")\n",
        "plt.ylabel(\"Stock Price\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print('Mean Absolute Error (MAE):', mae)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(10 ** (y_test), 10 ** (y_pred))\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "\n",
        "# Calculate Root Mean Squared Error (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "\n",
        "# Calculate R-squared (R2) Score\n",
        "r2 = r2_score(10 ** (y_test), 10 ** (y_pred))\n",
        "print(\"R-squared (R2) Score:\", r2)\n",
        "\n",
        "# Calculate Adjusted R-squared Score\n",
        "n = X_test.shape[0]  # Number of data points\n",
        "p = X_test.shape[1]  # Number of features\n",
        "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
        "print(\"Adjusted R-squared Score:\", adjusted_r2)\n"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***I have not used any hyperparameter optimization techniques ,Our model already gives a high accuracy so there is no need of any hyperparameter optimization technique.***"
      ],
      "metadata": {
        "id": "IfWKoGQtsklg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there is no hyperparameter optimization included in the code, there's no specific improvement to mention in terms of hyperparameter tuning."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2  ***Lasso Regression***"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Lasso regression model with specified alpha and max_iter values\n",
        "lasso = Lasso(alpha=0.1, max_iter=3000)\n",
        "\n",
        "# Fit the Lasso model to the training data\n",
        "lasso.fit(X_train, y_train)\n",
        "\n",
        "# Calculate the R-squared score on the training data\n",
        "train_score = lasso.score(X_train, y_train)\n",
        "print(\"R-squared (R2) Score on Training Data:\", train_score)\n",
        "\n",
        "# Predict the target values on the test data\n",
        "y_pred1 = lasso.predict(X_test)\n"
      ],
      "metadata": {
        "id": "E7FfQUvDFvtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred1)\n",
        "print('Mean Absolute Error (MAE):', mae)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(10 ** (y_test), 10 ** (y_pred1))\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "\n",
        "# Calculate Root Mean Squared Error (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "\n",
        "# Calculate R-squared (R2) Score\n",
        "r2 = r2_score(10 **(y_test), 10 **(y_pred1))\n",
        "print(\"R-squared (R2) Score:\", r2)\n",
        "\n",
        "# Calculate Adjusted R-squared Score\n",
        "n = X_test.shape[0]  # Number of data points\n",
        "p = X_test.shape[1]  # Number of features\n",
        "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
        "print(\"Adjusted R-squared Score:\", adjusted_r2)"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "# Fit the Algorithm\n",
        "# Create a Lasso regression model\n",
        "lasso1 = Lasso()\n",
        "\n",
        "# Define a set of alpha values for hyperparameter tuning\n",
        "parameters = {'alpha': [1e-15, 1e-13, 1e-10, 1e-8, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10, 20, 30, 40, 45, 50, 55, 60, 100]}\n",
        "\n",
        "# Initialize the GridSearchCV with cross-validation and negative mean squared error scoring\n",
        "lasso_regressor = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "\n",
        "# Fit the Lasso regressor with hyperparameter tuning to the training data\n",
        "lasso_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Print the best alpha parameter and its corresponding negative mean squared error\n",
        "print(\"The best alpha value is found to be:\", lasso_regressor.best_params_)\n",
        "print(\"\\nUsing alpha =\", lasso_regressor.best_params_['alpha'], \"the negative mean squared error is:\", -lasso_regressor.best_score_)\n",
        "\n",
        "# Predict on the model\n",
        "# Make predictions on the test data\n",
        "y_pred_lasso = lasso_regressor.predict(X_test)\n",
        "\n",
        "# Plot the predicted and actual values\n",
        "plt.figure(figsize=(18, 8))\n",
        "plt.plot(10 ** (y_pred_lasso), color='orange', label='Predicted')\n",
        "plt.plot(10 ** (np.array(y_test)), label='Actual')\n",
        "plt.legend([\"Predicted\", \"Actual\"],fontsize=12,loc='upper right')\n",
        "\n",
        "plt.xlabel('Data Points')\n",
        "plt.ylabel('Values')\n",
        "plt.title('Lasso Regression Predicted vs. Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***We have used Cross validation and hyper parameter tuning for avoiding overfiting of the model lasso and better accuracy on test data.***"
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Not much improvement is seen beacuse of the less accuracy than our first model***"
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Here all the evaluation metrics including MAE,MSE,MAPE,RMSE the lower there values are as good they are for our business out of choosing any one that can only be told at the end. R2 score here signies that 99.7 variance in dependent variable can be predicted by independent variable***"
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 ***Ridge Regression***"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Create a Ridge regression model\n",
        "ridge = Ridge()\n",
        "\n",
        "# Fit the Algorithm\n",
        "# Define a set of alpha values for hyperparameter tuning\n",
        "parameters = {'alpha': [1e-15, 1e-13, 1e-10, 1e-8, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10, 20, 30, 40, 45, 50, 55, 60, 100]}\n",
        "\n",
        "# Initialize the GridSearchCV with cross-validation\n",
        "ridge_regressor = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "\n",
        "# Fit the Ridge regressor with hyperparameter tuning to the training data\n",
        "ridge_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Print the best alpha parameter and its corresponding negative mean squared error\n",
        "print(\"The best alpha value is found to be:\", ridge_regressor.best_params_)\n",
        "print(\"\\nUsing alpha =\", ridge_regressor.best_params_['alpha'], \"the negative mean squared error is:\", -ridge_regressor.best_score_)\n",
        "\n",
        "# Fit the Ridge algorithm using the best alpha value\n",
        "ridge = Ridge(alpha=ridge_regressor.best_params_['alpha'])\n",
        "ridge.fit(X_train, y_train)\n",
        "\n",
        "# Print the R-squared score on the training data\n",
        "print(\"R-squared score on training data:\", ridge.score(X_train, y_train))\n",
        "\n",
        "# Predict on the model\n",
        "# Make predictions on the test data\n",
        "y_pred_r = ridge.predict(X_test)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "MSE = mean_squared_error(10**(y_test), 10**(y_pred_r))\n",
        "print(\"MSE:\", MSE)\n",
        "\n",
        "# Calculate Root Mean Squared Error (RMSE)\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE:\", RMSE)\n",
        "\n",
        "# Calculate R-squared (R2) score\n",
        "r2 = r2_score(10**(y_test), 10**(y_pred_r))\n",
        "print(\"R2:\", r2)\n",
        "\n",
        "# Calculate and print Adjusted R-squared score\n",
        "adjusted_r2 = 1 - (1 - r2) * ((X_test.shape[0] - 1) / (X_test.shape[0] - X_test.shape[1] - 1))\n",
        "print(\"Adjusted R2:\", adjusted_r2)\n"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Create a Ridge regression model\n",
        "ridge = Ridge()\n",
        "\n",
        "# Define a set of alpha hyperparameters for GridSearchCV\n",
        "parameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-5, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20, 30, 40, 45, 50, 55, 60, 100]}\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Perform hyperparameter optimization using GridSearchCV\n",
        "ridge_regressor = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "ridge_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Print the best alpha parameter found during optimization\n",
        "print(\"The best fit alpha value is found out to be:\", ridge_regressor.best_params_)\n",
        "print(\"Using\", ridge_regressor.best_params_, \"the negative mean squared error is:\", ridge_regressor.best_score_)\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "# Make predictions using the optimized Ridge model\n",
        "y_pred_ridge = ridge_regressor.predict(X_test)\n",
        "\n",
        "# Visualize predicted vs. actual values in colorful lines\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(10**(y_pred_ridge), color='aqua', label='Predicted', linewidth=2)\n",
        "plt.plot(10**(np.array(y_test)), color='coral', label='Actual', linewidth=2)\n",
        "plt.legend([\"Predicted\", \"Actual\"],fontsize=10,loc='upper right')\n",
        "plt.title('Predicted vs. Actual Values')\n",
        "plt.xlabel('Data Points')\n",
        "plt.ylabel('Values')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Detect heteroscedasticity by plotting colorful residuals\n",
        "residuals = 10**(y_test) - 10**(y_pred_ridge)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.scatter(10**(y_pred_ridge), residuals, color='purple', marker='o', s=10)\n",
        "plt.title('Residuals vs. Predicted Values')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The hyperparameter optimization technique that has been used in the above code is Grid Search. Grid Search is a brute-force approach to hyperparameter optimization, where the model is trained on a grid of different hyperparameter values. The model with the best performance on the validation data is selected as the final model.***"
      ],
      "metadata": {
        "id": "vBcvMRobqVyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Yes, there has been an improvement in the performance of the model after using Grid Search to optimize the hyperparameters.***"
      ],
      "metadata": {
        "id": "B-47ckz6qbMD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***According to my point of view , the MSE, RMSE, and R-squared values are all relatively low, which indicates that the model is a good fit. The adjusted R-squared value is also relatively high, which indicates that the model is a good fit even when the number of independent variables is large. This suggests that the model is likely to have a positive business impact.***"
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***We choose our first and third model that is simple linear regression model and ridge regression model for final prediction because of good prediction accuracy than lasso and least mean squared error and good scores of evalution metrics.***"
      ],
      "metadata": {
        "id": "XIFB7lWwqw4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The model explainability tool that I have used is the shap library. The shap library provides a number of tools for visualizing and understanding the explanations of machine learning models.***"
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Closing Price**: Closing Price of a stock refers to the final price at which the stock is traded on a particular stock exchange on a given trading day. It is the last price at which the stock is bought or sold during the trading session.\n",
        "\n",
        "**Importance** : The closing price is an important metric used by investors, analysts, and traders to evaluate a company’s financial health, market value, and stock performance. It is also used to calculate other important metrics such as the daily price change, market capitalization, and trading volume.\n",
        "\n",
        "**For an Average Investor** : An average investor sees investing in stocks for long-term purposes and in premium stocks that have proved to be quality and high-performing stocks over the years. For such investors, the daily closing price may not hold as high importance as for an average trader.\n",
        "\n",
        "**For a Traders** : For traders and analysts, the information on the closing price of stocks is essential to make sure that they make sound trading decisions and maximize returns on their portfolios.\n",
        "\n",
        "##In this project we did the following things  to get our desired results:-\n",
        "\n",
        " 1. At first we do the data wrangling then data cleaning and data transformation after that we do the Modeling part.\n",
        "\n",
        " 2. The trend of the price of Yes Bank's stock increased until 2018 and then Close,Open,High,Low price decreased.\n",
        "\n",
        " 3. Based on the open vs. close price graph, we concluded that Yes Bank's stock fell significantly after 2018.\n",
        "\n",
        " 4. Visualization has allowed us to notice that the closing price of the stock has suddenly fallen starting in 2018. It seems reasonable that the Yes Bank stock price was significantly impacted by the Rana Kapoor case fraud.\n",
        "\n",
        " 5. High, Low, Open are directly correlate with the Closing price of stocks.\n",
        "\n",
        " 6. The target variable is highly dependent on input variables.\n",
        "\n",
        " 7. Linear Regression has given the best results with lowest MAE, MSE, RMSE and MAPE scores.\n",
        "\n",
        " 8. Ridge regression shrunk the parameters to reduce complexity and multicollinearity, but ended up affecting the evaluation metrics.\n",
        "\n",
        " 9. Lasso regression did feature selection and ended up giving up worse results than ridge which again reflects the fact that each feature is important (as previously discussed).\n",
        "\n",
        " 10. The accuracy for each model is more than 90%."
      ],
      "metadata": {
        "id": "E-JVhCjera1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}
